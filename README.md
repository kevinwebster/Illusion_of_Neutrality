# Illusion_of_Neutrality
Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Résumé Screening

This repository contains the full dataset and experimental materials for the paper, "Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Résumé Screening."

Author: Kevin T. Webster, MBA

Contact: kevinwebster@gmail.com

LinkedIn: linkedin.com/in/kevintwebster

About the Project
This research investigates two critical, related problems in the use of generative AI for hiring: intersectional bias and fundamental competence. Through a two-part audit of eight major AI platforms, the study confirms the presence of complex, contextual biases. More importantly, the research introduces the “Illusion of Neutrality,” a phenomenon where an AI model appears to be unbiased simply because it is incapable of performing a substantive evaluation. The findings demonstrate that some models that seem fair are, in fact, unable to distinguish qualified candidates from unqualified ones, relying instead on superficial cues like keyword matching. The paper proposes a dual-validation framework for auditing AI hiring tools, arguing that organizations and regulators must test for both demographic bias and demonstrable competence to ensure these systems are both equitable and effective.

Repository Contents:
All of my data, resume versions, and AI prompts. Technically, you could take all of this and perfectly replicate my study

Data preserved with Zenodo as well: https://doi.org/10.5281/zenodo.15815581
