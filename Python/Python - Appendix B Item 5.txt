# -*- coding: utf-8 -*-
"""
Analysis Notebook for "Fairness Is Not Enough" - Experiment 1

This notebook replicates the statistical analysis for Appendix B, Item 5.
It analyzes the main effect of racial bias by comparing Black, Hispanic, 
and White candidate ratings against the control group.
"""

# =============================================================================
# 1. SETUP: LOAD LIBRARIES AND DATA
# =============================================================================
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind
from itertools import product

# --- Load the dataset ---
# In Google Colab, you must first upload your "Combined Data.csv" file.
try:
    df = pd.read_csv('Combined Data.csv')
    print("Successfully loaded 'Combined Data.csv'")
    print("Data shape:", df.shape)

    # --- Standardize column names to lowercase for consistency ---
    df.columns = [col.lower() for col in df.columns]
    print("Standardized column headers:", df.columns.tolist())

except FileNotFoundError:
    print("Error: 'Combined Data.csv' not found.")
    print("Please make sure you have uploaded the file to your Google Colab environment.")
    df = pd.DataFrame() # Create an empty dataframe to avoid further errors

# =============================================================================
# 2. DATA PREPARATION
# =============================================================================
if not df.empty:
    # --- Feature Engineering ---
    # Combine 'ai' and 'speed' into a single 'ai_model' column.
    df['ai_model'] = df['ai'] + '-' + df['speed']
    
    # --- Correctly Identify and Label the Control Group ---
    # The control group is identified by having a blank/null value in the 'race' column.
    control_mask = df['race'].isnull()
    df.loc[control_mask, 'race'] = 'Control'
    
    # Let's confirm that we found the control rows.
    num_control_rows = df['race'].value_counts().get('Control', 0)
    print(f"\nFound and labeled {num_control_rows} control rows.")

    print("\n--- Data after preparation ---")
    # Display a sample of rows to verify the data looks correct.
    print(df[['ai_model', 'job_type', 'rating', 'race', 'gender']].sample(5))


# =============================================================================
# 5. ANALYSIS 5: RACIAL BIAS (MAIN EFFECT)
# =============================================================================
# This section replicates Appendix B, Item 5.
# It performs t-tests to compare the mean ratings of Black, Hispanic, and
# White candidates against the Control group for each AI model and job type.

if not df.empty and num_control_rows > 0:
    print("\n\n--- Analysis 5: Racial Bias (Main Effect) ---")

    # Get unique models and job types to loop through
    models = df['ai_model'].unique()
    job_types = df['job_type'].unique()
    racial_groups = ['Black', 'Hispanic', 'White']
    
    # Prepare a list to store the results
    racial_bias_results = []

    # Loop through each model and job type combination
    for model, job_type in product(models, job_types):
        # Filter data for the current slice
        current_slice = df[(df['ai_model'] == model) & (df['job_type'] == job_type)]
        
        # Isolate the ratings for the control group
        control_ratings = current_slice[current_slice['race'] == 'Control']['rating']
        
        # Initialize a dictionary to hold the results for this row
        result = {
            'AI Model': model,
            'Job Type': job_type
        }

        # Loop through each racial group to compare against the control
        for group in racial_groups:
            group_ratings = current_slice[current_slice['race'] == group]['rating']
            
            # Initialize values
            mean_delta = np.nan
            p_value = np.nan

            # Perform calculation if data exists for both groups
            if len(group_ratings) > 1 and len(control_ratings) > 1:
                mean_delta = group_ratings.mean() - control_ratings.mean()
                _, p_value = ttest_ind(group_ratings, control_ratings, equal_var=False)
            
            # Add the results to the dictionary with dynamic keys
            result[f'Mean Î” ({group})'] = mean_delta
            result[f'p-Value ({group})'] = p_value
            
        racial_bias_results.append(result)

    # Convert the list of results into a DataFrame
    final_df = pd.DataFrame(racial_bias_results)
    
    # Sort for better readability
    final_df = final_df.sort_values(by=['AI Model', 'Job Type']).reset_index(drop=True)

    print("Racial Bias (Main Effect) vs. Control Group:")
    print(final_df.to_string())


print("\n\nAnalysis Complete.")
