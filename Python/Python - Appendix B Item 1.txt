# -*- coding: utf-8 -*-
"""
Analysis Notebook for "Fairness Is Not Enough" - Experiment 1

This notebook replicates the statistical analysis for Appendix B, Item 1.
It performs a one-way ANOVA to confirm that the AI models rated the three
distinct job types (and their corresponding résumés) differently.
"""

# =============================================================================
# 1. SETUP: LOAD LIBRARIES AND DATA
# =============================================================================
import pandas as pd
import numpy as np
from scipy.stats import f_oneway
import statsmodels.api as sm
from statsmodels.formula.api import ols
from itertools import product

# --- Load the dataset ---
# In Google Colab, you must first upload your "Combined Data.csv" file.
try:
    df = pd.read_csv('Combined Data.csv')
    print("Successfully loaded 'Combined Data.csv'")
    print("Data shape:", df.shape)

    # --- Standardize column names to lowercase for consistency ---
    df.columns = [col.lower() for col in df.columns]
    print("Standardized column headers:", df.columns.tolist())

except FileNotFoundError:
    print("Error: 'Combined Data.csv' not found.")
    print("Please make sure you have uploaded the file to your Google Colab environment.")
    df = pd.DataFrame() # Create an empty dataframe to avoid further errors

# =============================================================================
# 2. DATA PREPARATION
# =============================================================================
if not df.empty:
    # --- Feature Engineering ---
    # Combine 'ai' and 'speed' into a single 'ai_model' column.
    df['ai_model'] = df['ai'] + '-' + df['speed']
    
    # --- Correctly Identify and Label the Control Group ---
    # The control group is identified by having a blank/null value in the 'race' column.
    control_mask = df['race'].isnull()
    df.loc[control_mask, 'race'] = 'Control'
    
    # Let's confirm that we found the control rows.
    num_control_rows = df['race'].value_counts().get('Control', 0)
    print(f"\nFound and labeled {num_control_rows} control rows.")

    # --- Create Intersectional Group Column ---
    df['race_gender'] = df['race'].fillna('') + ' ' + df['gender'].fillna('')
    df.loc[df['race'] == 'Control', 'race_gender'] = 'Control'

    print("\n--- Data after preparation ---")
    # Display a sample of rows to verify the new columns.
    print(df[['ai_model', 'job_type', 'rating', 'race', 'gender', 'race_gender']].sample(5))


# =============================================================================
# 3. ANALYSIS 1: RATING DIFFERENTIATION BY JOB TYPE (ANOVA)
# =============================================================================
# This section replicates Appendix B, Item 1.
# It runs a one-way ANOVA for each AI model to test if there is a statistically
# significant difference in the mean ratings across the three job types
# (Finance, HR, and Fraud).

if not df.empty:
    print("\n\n--- Analysis 1: ANOVA for Job Type Differentiation ---")
    
    # Get a list of the unique AI models to loop through
    models = df['ai_model'].unique()
    
    # Prepare a list to store the results
    anova_results = []
    
    # Loop through each model
    for model in models:
        # Filter the dataframe for the current model
        model_df = df[df['ai_model'] == model]
        
        # --- Prepare data for ANOVA ---
        # Create a list of rating arrays, one for each job type
        # For example: [ [ratings_for_finance], [ratings_for_hr], [ratings_for_fraud] ]
        grouped_ratings = [
            model_df[model_df['job_type'] == job]['rating']
            for job in model_df['job_type'].unique()
        ]
        
        # --- Perform the one-way ANOVA ---
        # The star (*) unpacks the list into separate arguments for the function
        f_stat, p_value = f_oneway(*grouped_ratings)
        
        # --- Get Degrees of Freedom ---
        # df between groups = number of groups - 1
        df_between = len(grouped_ratings) - 1
        # df within groups = total samples - number of groups
        df_within = len(model_df) - len(grouped_ratings)
        
        # Store the results
        anova_results.append({
            'AI Model': model,
            'df': f"({df_between}, {df_within})",
            'F-Statistic': f_stat,
            'p-value': p_value
        })
        
    # Convert the results list to a pandas DataFrame for nice printing
    results_df = pd.DataFrame(anova_results)
    
    # Add a column to indicate significance
    results_df['Significant (p < 0.001)'] = results_df['p-value'] < 0.001
    
    # Sort the results alphabetically by model name
    results_df = results_df.sort_values(by='AI Model').reset_index(drop=True)
    
    print("One-Way ANOVA Results (Rating by Job Type):")
    print(results_df.to_string())

print("\n\nAnalysis Complete.")
