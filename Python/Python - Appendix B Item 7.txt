# -*- coding: utf-8 -*-
"""
Analysis Notebook for "Fairness Is Not Enough" - Experiment 1

This notebook replicates the statistical analysis for Appendix B, Item 7.
It analyzes bias interaction effects using a two-way ANOVA to test if
the effect of a candidate's gender on their rating depends on their race.
"""

# =============================================================================
# 1. SETUP: LOAD LIBRARIES AND DATA
# =============================================================================
import pandas as pd
import numpy as np
import statsmodels.api as sm
from statsmodels.formula.api import ols
from itertools import product

# --- Load the dataset ---
# In Google Colab, you must first upload your "Combined Data.csv" file.
try:
    df = pd.read_csv('Combined Data.csv')
    print("Successfully loaded 'Combined Data.csv'")
    print("Data shape:", df.shape)

    # --- Standardize column names to lowercase for consistency ---
    df.columns = [col.lower() for col in df.columns]
    print("Standardized column headers:", df.columns.tolist())

except FileNotFoundError:
    print("Error: 'Combined Data.csv' not found.")
    print("Please make sure you have uploaded the file to your Google Colab environment.")
    df = pd.DataFrame() # Create an empty dataframe to avoid further errors

# =============================================================================
# 2. DATA PREPARATION
# =============================================================================
if not df.empty:
    # --- Feature Engineering ---
    # Combine 'ai' and 'speed' into a single 'ai_model' column.
    df['ai_model'] = df['ai'] + '-' + df['speed']
    
    # --- Correctly Identify and Label the Control Group ---
    # The control group is identified by having a blank/null value in the 'race' column.
    control_mask = df['race'].isnull()
    df.loc[control_mask, 'race'] = 'Control'
    df.loc[control_mask, 'gender'] = 'Control' # Also label gender for control
    
    # Let's confirm that we found the control rows.
    num_control_rows = df['race'].value_counts().get('Control', 0)
    print(f"\nFound and labeled {num_control_rows} control rows.")


# =============================================================================
# 7. ANALYSIS 7: BIAS INTERACTION EFFECTS (TWO-WAY ANOVA)
# =============================================================================
# This section replicates Appendix B, Item 7.
# A two-way ANOVA tests for "interaction effects." In our case, it answers:
# "Does the effect of a candidate's Gender on their rating DEPEND on their Race?"
# If the interaction is significant, it means the biases aren't simple; they are intersectional.

if not df.empty and num_control_rows > 0:
    print("\n\n--- Analysis 7: Bias Interaction Effects (Two-Way ANOVA) ---")
    
    # We only want to analyze the non-control data for this test
    analysis_df = df[df['race'] != 'Control'].copy()

    # Get unique models and job types to loop through
    models = analysis_df['ai_model'].unique()
    job_types = analysis_df['job_type'].unique()
    
    # Prepare a list to store the results
    anova_results = []

    # Loop through each model and job type combination
    for model, job_type in product(models, job_types):
        # Filter data for the current slice
        current_df = analysis_df[(analysis_df['ai_model'] == model) & (analysis_df['job_type'] == job_type)]
        
        # Ensure there's enough data to run the model
        if len(current_df) > 10:
            try:
                # --- Define and fit the ANOVA model ---
                # Formula: rating is explained by race, gender, and their interaction (race * gender)
                # The C() wrapper tells statsmodels to treat these as categorical variables.
                model_fit = ols('rating ~ C(race) * C(gender)', data=current_df).fit()
                
                # Get the ANOVA table
                anova_table = sm.stats.anova_lm(model_fit, typ=2)
                
                # Get the residual degrees of freedom
                df_residual = int(anova_table.loc['Residual', 'df'])

                # --- Process the anova_table to extract results for each effect ---
                # We exclude the 'Residual' row from the main output table
                for effect in anova_table.index:
                    if effect == 'Residual':
                        continue

                    # The effect names are like 'C(race)', 'C(gender)', 'C(race):C(gender)'
                    # We'll clean them up for the final table.
                    clean_effect_name = effect.replace('C(', '').replace(')', '').replace(':', ':')
                    df_factor = int(anova_table.loc[effect, 'df'])
                    
                    anova_results.append({
                        'AI Model': model,
                        'Job Type': job_type,
                        'Effect': clean_effect_name,
                        'F-Statistic': anova_table.loc[effect, 'F'],
                        'p-Value': anova_table.loc[effect, 'PR(>F)']
                    })

            except Exception as e:
                # This can happen if there's not enough data variation for a slice
                print(f"Could not run ANOVA for {model}, {job_type}. Reason: {e}")

    # Convert the list of results into a DataFrame
    final_df = pd.DataFrame(anova_results)
    
    # Sort for better readability
    final_df = final_df.sort_values(by=['AI Model', 'Job Type', 'Effect']).reset_index(drop=True)

    print("Two-Way ANOVA Results for Bias Interaction Effects:")
    print(final_df.to_string())
    
    print("\n--- Significant Interaction Effects (p <= 0.05) ---")
    # Filter for only the interaction effect and where p-value is significant
    significant_interactions = final_df[
        (final_df['Effect'] == 'race:gender') & 
        (final_df['p-Value'] <= 0.05)
    ]
    print(significant_interactions.to_string())


print("\n\nAnalysis Complete.")
