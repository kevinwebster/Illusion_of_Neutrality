# -*- coding: utf-8 -*-
"""
Analysis Notebook for "Fairness Is Not Enough" - Experiment 1

This notebook replicates the statistical analysis for Appendix B, Item 6.
It analyzes intersectional bias by comparing each race-gender group 
(e.g., "Black Female") against the control group.
"""

# =============================================================================
# 1. SETUP: LOAD LIBRARIES AND DATA
# =============================================================================
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind
from itertools import product

# --- Load the dataset ---
# In Google Colab, you must first upload your "Combined Data.csv" file.
try:
    df = pd.read_csv('Combined Data.csv')
    print("Successfully loaded 'Combined Data.csv'")
    print("Data shape:", df.shape)

    # --- Standardize column names to lowercase for consistency ---
    df.columns = [col.lower() for col in df.columns]
    print("Standardized column headers:", df.columns.tolist())

except FileNotFoundError:
    print("Error: 'Combined Data.csv' not found.")
    print("Please make sure you have uploaded the file to your Google Colab environment.")
    df = pd.DataFrame() # Create an empty dataframe to avoid further errors

# =============================================================================
# 2. DATA PREPARATION
# =============================================================================
if not df.empty:
    # --- Feature Engineering ---
    # Combine 'ai' and 'speed' into a single 'ai_model' column.
    df['ai_model'] = df['ai'] + '-' + df['speed']
    
    # --- Correctly Identify and Label the Control Group ---
    # The control group is identified by having a blank/null value in the 'race' column.
    control_mask = df['race'].isnull()
    df.loc[control_mask, 'race'] = 'Control'
    df.loc[control_mask, 'gender'] = 'Control' # Also label gender for control

    # --- Create Intersectional Group Column ---
    # We use .fillna('') to handle any potential blank cells gracefully.
    df['race_gender'] = df['race'].fillna('') + ' ' + df['gender'].fillna('')
    # Clean up the control group's intersectional name to be just 'Control'.
    df.loc[df['race'] == 'Control', 'race_gender'] = 'Control'
    
    # Let's confirm that we found the control rows.
    num_control_rows = df['race'].value_counts().get('Control', 0)
    print(f"\nFound and labeled {num_control_rows} control rows.")

    print("\n--- Data after preparation ---")
    # Display a sample of rows to verify the data looks correct.
    print(df[['ai_model', 'job_type', 'rating', 'race', 'gender', 'race_gender']].sample(5))


# =============================================================================
# 6. ANALYSIS 6: INTERSECTIONAL BIAS
# =============================================================================
# This section replicates Appendix B, Item 6.
# It performs t-tests to compare the mean ratings of each specific race-gender
# group against the Control group and calculates the effect size (Cohen's d).

if not df.empty and num_control_rows > 0:
    print("\n\n--- Analysis 6: Intersectional Bias ---")

    # --- Helper function to calculate Cohen's d ---
    def cohen_d(x, y):
        n1, n2 = len(x), len(y)
        if n1 < 2 or n2 < 2: return 0
        s1, s2 = np.var(x, ddof=1), np.var(y, ddof=1)
        # Handle cases where variance is zero or calculation is not possible
        if (n1 + n2 - 2) <= 0: return 0
        pooled_std = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))
        if pooled_std == 0: return 0
        mean1, mean2 = np.mean(x), np.mean(y)
        return (mean1 - mean2) / pooled_std

    # --- Prepare for the analysis ---
    models = df['ai_model'].unique()
    job_types = df['job_type'].unique()
    # Get all demographic groups except for the control group
    demographic_groups = df[df['race_gender'] != 'Control']['race_gender'].unique()

    intersectional_results = []

    # --- Loop through every combination ---
    for model, job_type, group in product(models, job_types, demographic_groups):
        current_slice = df[(df['ai_model'] == model) & (df['job_type'] == job_type)]
        
        control_ratings = current_slice[current_slice['race_gender'] == 'Control']['rating']
        group_ratings = current_slice[current_slice['race_gender'] == group]['rating']
        
        # Initialize values
        demo_effect = np.nan
        p_value = np.nan
        d_effect = np.nan

        # Perform calculation if data exists for both groups
        if len(group_ratings) > 1 and len(control_ratings) > 1:
            demo_effect = group_ratings.mean() - control_ratings.mean()
            _, p_value = ttest_ind(group_ratings, control_ratings, equal_var=False)
            d_effect = cohen_d(group_ratings, control_ratings)
        
        intersectional_results.append({
            'AI Model': model,
            'Job Type': job_type,
            'Demographic Group': group,
            'Demo Effect': demo_effect,
            'p-Value': p_value,
            "Cohen's |d|": abs(d_effect)
        })

    # Convert the list of results into a DataFrame
    final_df = pd.DataFrame(intersectional_results)
    
    # Sort for better readability
    final_df = final_df.sort_values(by=['AI Model', 'Job Type', 'Demographic Group']).reset_index(drop=True)

    print("Intersectional Bias vs. Control Group:")
    print(final_df.to_string())


print("\n\nAnalysis Complete.")
